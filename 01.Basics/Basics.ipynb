{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Arithmetic with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Tensor data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor(6)\n",
    "print(t)\n",
    "print(t.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor(6,dtype=torch.float)\n",
    "print(t)\n",
    "print(t.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can assign your own data type also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor(6.)\n",
    "print(t)\n",
    "print(t.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here 6. is a shorthand for 6.0. which is indicate that you want to create a floating point number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Tensor shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "torch.int64\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([1,2,3])\n",
    "print(t)\n",
    "print(t.dtype)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "torch.float32\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([1.,2,3])\n",
    "print(t)\n",
    "print(t.dtype)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensor can contains only same type of data. So when we placed one of them as float it will cast all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1,2,3])\n",
    "print(t1)\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(t2)\n",
    "print(t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]]])\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])\n",
    "print(t3)\n",
    "print(t3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors can have any number of dimensions, and different lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's construct a 5x3 matrix, uninitialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6051, 0.1358, 0.6353],\n",
      "        [0.2691, 0.3063, 0.6831],\n",
      "        [0.2838, 0.1827, 0.1648],\n",
      "        [0.9129, 0.4145, 0.2376],\n",
      "        [0.2003, 0.8000, 0.4764]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(5, 3)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Tensor transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(t)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose\n",
    "t.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose (via permute)\n",
    "t.permute(-1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Tensor Reshape with iew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape with view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape with view again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(6,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Tensor Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: torch.Size([2, 3])\n",
      "Number of dimensions: 2\n",
      "Tensor type: torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Some tensor info\n",
    "print('Tensor shape:', t.shape)   # t.size() gives the same\n",
    "print('Number of dimensions:', t.dim())\n",
    "print('Tensor type:', t.type())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Tensor addition</h5>\n",
    "The element-wise addition of two tensors with the same dimensions results in a new tensor with \n",
    "the same dimensions where each scalar value is the element-wise addition of the scalars in the parent tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1079, 0.6118, 0.2685],\n",
      "        [0.7571, 0.8914, 0.6529],\n",
      "        [0.1761, 0.8397, 0.0274],\n",
      "        [0.4298, 0.6917, 0.0563]])\n",
      "tensor([[0.8508, 0.3559, 0.8427],\n",
      "        [0.3772, 0.0776, 0.1198],\n",
      "        [0.6341, 0.7408, 0.2053],\n",
      "        [0.6422, 0.7413, 0.2769]])\n",
      "tensor([[0.9586, 0.9677, 1.1111],\n",
      "        [1.1343, 0.9690, 0.7726],\n",
      "        [0.8103, 1.5804, 0.2328],\n",
      "        [1.0720, 1.4329, 0.3331]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(4,3)\n",
    "t2 = torch.rand(4,3)\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t1 + t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Tensor Product</h5>\n",
    "Performs a matrix multiplication of the matrices mat1 and mat2.\n",
    "\n",
    "If matrix1 is a (n×m) tensor, matrix2 is a (m×p) tensor, out will be a (n×p) tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7409, 0.7977, 0.2156],\n",
      "        [0.0706, 0.5236, 0.7165]])\n",
      "tensor([[0.0690, 0.4489],\n",
      "        [0.3888, 0.3288],\n",
      "        [0.6119, 0.2801]])\n",
      "tensor([[0.4932, 0.6553],\n",
      "        [0.6469, 0.4046]])\n"
     ]
    }
   ],
   "source": [
    "m1 = torch.rand(2,3)\n",
    "m2 = torch.rand(3,2)\n",
    "m3 = torch.mm(m1,m2)\n",
    "print(m1)\n",
    "print(m2)\n",
    "print(m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>PyTorch Tensor To and From Numpy ndarray</h5>\n",
    "\n",
    "You can easily create a tensors from an ndarray and vice versa. \n",
    "These operations are fast, since the data of both structures will share the same memory space, \n",
    "and so no copying is involved. This is obviously an efficient approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy ndarray to PyTorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.41749337 -0.00234322 -0.73671071 -0.81345565 -1.17166277]\n",
      " [-1.29763645 -1.28002106  1.4760002   0.30410244 -0.32425006]\n",
      " [ 1.80540072 -0.80574011 -1.85814052 -0.66605284  0.66771691]]\n",
      "tensor([[-0.4175, -0.0023, -0.7367, -0.8135, -1.1717],\n",
      "        [-1.2976, -1.2800,  1.4760,  0.3041, -0.3243],\n",
      "        [ 1.8054, -0.8057, -1.8581, -0.6661,  0.6677]], dtype=torch.float64)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "np_a = numpy.random.randn(3,5)\n",
    "t = torch.from_numpy(np_a)\n",
    "print(np_a)\n",
    "print(t)\n",
    "print(type(np_a))\n",
    "print(type(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch tensor to Numpy ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9423, 0.7826, 0.3643, 0.9560, 0.3057],\n",
      "        [0.6873, 0.0147, 0.0791, 0.5373, 0.8679],\n",
      "        [0.8345, 0.9230, 0.9378, 0.8177, 0.0743]])\n",
      "[[0.94228536 0.782649   0.36426556 0.9559813  0.30567437]\n",
      " [0.68726057 0.01474398 0.07914484 0.5373291  0.86793417]\n",
      " [0.8345047  0.9229511  0.93779755 0.8177026  0.07431334]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(3,5)\n",
    "np_a = t.numpy()\n",
    "print(t)\n",
    "print(np_a)\n",
    "print(type(np_a))\n",
    "print(type(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Tensor operations and gradients</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors.\n",
    "x1 = torch.tensor(2.)\n",
    "w1 = torch.tensor(5., requires_grad=True)\n",
    "b = torch.tensor(7., requires_grad=True)\n",
    "\n",
    "x2 = torch.tensor(2., requires_grad=True)\n",
    "w2 = torch.tensor(5., requires_grad=True)\n",
    "b2 = torch.tensor(7., requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "requires_grad indicates whether a variable is trainable. \n",
    "By default, requires_grad is False in creating a Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = w1 * x1 + w2 * x2 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: tensor(2.)\n",
      "x2: tensor(2., requires_grad=True)\n",
      "w1: tensor(5., requires_grad=True)\n",
      "w2: tensor(5., requires_grad=True)\n",
      "b: tensor(7., requires_grad=True)\n",
      "y: tensor(27., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"x1:\",x1)\n",
    "print(\"x2:\",x2)\n",
    "print(\"w1:\",w1)\n",
    "print(\"w2:\",w2)\n",
    "print(\"b:\",b)\n",
    "print(\"y:\",y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It performs the backpropagation starting from a variable. \n",
    "In deep learning, this variable often holds the value of the cost function. \n",
    "Backward executes the backward pass and computes all the backpropagation gradients automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the derivatives, we can call the .backward method on our result y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y.backward()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivates of y w.r.t the input tensors are stored in the .grad property of the respective tensors.\n",
    "Display gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx1: None\n",
      "dy/dx2: tensor(5.)\n",
      "dy/dw1: tensor(2.)\n",
      "dy/dw2: tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "print('dy/dx1:', x1.grad)\n",
    "print('dy/dx2:', x2.grad)\n",
    "print('dy/dw1:', w1.grad)\n",
    "print('dy/dw2:', w1.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that x1.grad is None, because x doesn't have requires_grad set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
